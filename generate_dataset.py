#!/usr/bin/env python3
"""
å¢å¼ºå‹æ•°æ®é›†ç”Ÿæˆå™¨ï¼šå®Œå…¨é…ç½®åŒ–ï¼Œç”Ÿäº§å°±ç»ª
ä¿®å¤é—®é¢˜ï¼š
1. ç¡¬æ¡ˆä¾‹è¡¨æœªæ³¨å†Œåˆ°æ ‡æ³¨ç³»ç»Ÿ
2. ç›¸ä¼¼åº¦æ ‡ç­¾ä¸åˆç†ï¼ˆé¢å¤–å­—æ®µæ ‡æ³¨ä¸º1.0ï¼‰
3. è·¨batchæ¢¯åº¦è€¦åˆ
4. ç¼ºå¤±æ•°æ®å®Œæ•´æ€§æ£€æŸ¥
5. è¿‡åº¦å½’ä¸€åŒ–å‰ç½®
"""
import argparse
import mysql.connector
from sqlalchemy import create_engine
from typing import List, Dict, Tuple, Set
import pandas as pd
import numpy as np
import yaml
import os
import json
import random
from datetime import datetime, timedelta
import itertools
import hashlib
from collections import defaultdict


class EnhancedDatasetGenerator:
    """
    ç”Ÿäº§çº§æ•°æ®é›†ç”Ÿæˆå™¨
    æ‰€æœ‰å‚æ•°ä» config.yml è¯»å–ï¼Œä»£ç ä¸­æ— ç¡¬ç¼–ç 
    å†…ç½®æ•°æ®è´¨é‡éªŒè¯æœºåˆ¶
    """

    # é»˜è®¤é…ç½®æ–‡ä»¶è·¯å¾„
    DEFAULT_CONFIG_PATH = "config.yml"

    def __init__(self, config_path: str = None):
        if config_path is None:
            config_path = self.DEFAULT_CONFIG_PATH

        if not os.path.exists(config_path):
            raise FileNotFoundError(f"âŒ é…ç½®æ–‡ä»¶æœªæ‰¾åˆ°: {config_path}")

        with open(config_path, 'r', encoding='utf-8') as f:
            self.config = yaml.safe_load(f)

        # åŠ è½½MySQLé…ç½®
        mysql_cfg = self.config.get('mysql', {})
        self.mysql_host = mysql_cfg.get('host', 'localhost')
        self.mysql_user = mysql_cfg.get('user', 'root')
        self.mysql_password = mysql_cfg.get('password', '')
        self.mysql_port = mysql_cfg.get('port', 3306)
        self.mysql_database = mysql_cfg.get('database', 'table_similarity')

        # åˆ›å»ºSQLAlchemyè¿æ¥å¼•æ“
        self.engine = create_engine(
            f"mysql+mysqlconnector://{self.mysql_user}:{self.mysql_password}"
            f"@{self.mysql_host}:{self.mysql_port}/{self.mysql_database}",
            pool_pre_ping=True,  # è¿æ¥æ± å¥åº·æ£€æŸ¥
            echo=False
        )

        # ç”Ÿæˆå‚æ•°é…ç½®
        gen_cfg = self.config.get('data_generation', {})
        self.sample_size = gen_cfg.get('samples_per_table', 1000)
        self.base_tables_per_theme = gen_cfg.get('base_tables_per_theme', 5)
        self.variations_per_table = gen_cfg.get('variations_per_table', 3)
        self.min_fields = gen_cfg.get('min_fields_per_table', 5)
        self.max_fields = gen_cfg.get('max_fields_per_table', 15)
        self.synonym_prob = gen_cfg.get('synonym_prob', 0.3)
        self.extra_field_prob = gen_cfg.get('extra_field_prob', 0.3)
        self.missing_field_prob = gen_cfg.get('missing_field_prob', 0.2)

        # ç›¸ä¼¼åº¦é˜ˆå€¼é…ç½®
        sim_thresh = gen_cfg.get('similarity_thresholds', {})
        self.high_sim_threshold = sim_thresh.get('high', 0.8)
        self.medium_sim_threshold = sim_thresh.get('medium', 0.6)
        self.low_sim_threshold = sim_thresh.get('low', 0.3)
        self.hard_min_threshold = sim_thresh.get('hard_min', 0.4)
        self.hard_max_threshold = sim_thresh.get('hard_max', 0.6)

        # åŠ è½½æ¨¡æ¿å’Œä¸»é¢˜
        self._load_templates_and_themes()

        # æ•°æ®è´¨é‡è¿½è¸ª
        self.generation_metadata = {
            'tables_created': [],
            'synonym_replacements': defaultdict(list),
            'field_coverage': defaultdict(set),
            'similarity_distribution': []
        }

        print(f"âœ… æ•°æ®é›†ç”Ÿæˆå™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"   é…ç½®æ–‡ä»¶: {config_path}")
        print(f"   MySQLæ•°æ®åº“: {self.mysql_database}@{self.mysql_host}:{self.mysql_port}")
        print(f"   é‡‡æ ·è¡Œæ•°: {self.sample_size}")
        print(f"   ä¸»é¢˜æ•°: {len(self.themes)}")
        print(f"   å­—æ®µæ¨¡æ¿æ•°: {len(self.field_templates)}")

    def _get_db_connection(self):
        """è·å–MySQLæ•°æ®åº“è¿æ¥ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰"""
        try:
            return mysql.connector.connect(
                host=self.mysql_host,
                user=self.mysql_user,
                password=self.mysql_password,
                port=self.mysql_port,
                database=self.mysql_database,
                charset='utf8mb4',
                connect_timeout=10
            )
        except mysql.connector.Error as e:
            print(f"âŒ æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
            raise

    def _load_templates_and_themes(self):
        """ä»é…ç½®åŠ è½½å­—æ®µæ¨¡æ¿å’Œä¸šåŠ¡ä¸»é¢˜ï¼ˆæ”¯æŒå¤–éƒ¨æ‰©å±•ï¼‰"""
        # å­—æ®µæ¨¡æ¿å®šä¹‰ï¼ˆåŒ…å«å­—æ®µæè¿°å’ŒåŒä¹‰è¯ï¼‰
        self.field_templates = {
            'currency_code': {
                'type': 'VARCHAR(10)',
                'description': 'è´§å¸ä»£ç ï¼Œå¦‚CNYã€USDï¼Œç¬¦åˆISO 4217æ ‡å‡†',
                'generator': self._gen_currency_code,
                'synonyms': ['fx_code', 'cur_code', 'currency', 'ccy', 'money_type'],
                'business_domain': 'finance'
            },
            'exchange_rate': {
                'type': 'DECIMAL(20,6)',
                'description': 'è´§å¸å…‘æ¢æ±‡ç‡å€¼ï¼Œå®æ—¶å¸‚åœºæ±‡ç‡',
                'generator': self._gen_rate,
                'synonyms': ['fx_rate', 'rate', 'conversion_rate', 'ex_rate', 'currency_rate'],
                'business_domain': 'finance'
            },
            'date': {
                'type': 'DATE',
                'description': 'äº¤æ˜“æ—¥æœŸæˆ–ä¸šåŠ¡æ—¥æœŸï¼Œæ ¼å¼YYYY-MM-DD',
                'generator': self._gen_date,
                'synonyms': ['trans_date', 'value_date', 'order_date', 'create_date', 'txn_date', 'biz_date'],
                'business_domain': 'common'
            },
            'amount': {
                'type': 'DECIMAL(20,2)',
                'description': 'äº¤æ˜“é‡‘é¢æˆ–æ•°å€¼ï¼Œå•ä½ï¼šå…ƒ',
                'generator': self._gen_amount,
                'synonyms': ['tx_amount', 'value', 'amt', 'transaction_amount', 'total_amount', 'sum'],
                'business_domain': 'common'
            },
            'account_id': {
                'type': 'BIGINT',
                'description': 'è´¦æˆ·å”¯ä¸€æ ‡è¯†ç¬¦ï¼Œç³»ç»Ÿå†…éƒ¨ID',
                'generator': self._gen_id,
                'synonyms': ['acct_id', 'account_number', 'acc_id', 'primary_account_id', 'client_id'],
                'business_domain': 'account'
            },
            'status': {
                'type': 'VARCHAR(20)',
                'description': 'è®°å½•çŠ¶æ€ï¼ˆactive/pending/closedï¼‰',
                'generator': self._gen_status,
                'synonyms': ['state', 'record_status', 'active_status', 'status_code', 'record_state'],
                'business_domain': 'common'
            },
            'region': {
                'type': 'VARCHAR(50)',
                'description': 'åœ°ç†åŒºåŸŸæˆ–ä¸šåŠ¡åŒºåŸŸ',
                'generator': self._gen_region,
                'synonyms': ['area', 'location', 'territory', 'zone', 'district', 'province'],
                'business_domain': 'geo'
            },
            'user_id': {
                'type': 'BIGINT',
                'description': 'ç”¨æˆ·å”¯ä¸€æ ‡è¯†ç¬¦',
                'generator': self._gen_id,
                'synonyms': ['customer_id', 'client_id', 'member_id', 'uid', 'person_id'],
                'business_domain': 'user'
            },
            'email': {
                'type': 'VARCHAR(100)',
                'description': 'ç”µå­é‚®ç®±åœ°å€',
                'generator': self._gen_email,
                'synonyms': ['mail', 'email_address', 'contact_email', 'e_mail'],
                'business_domain': 'contact'
            },
            'phone': {
                'type': 'VARCHAR(20)',
                'description': 'è”ç³»ç”µè¯å·ç ',
                'generator': self._gen_phone,
                'synonyms': ['mobile', 'telephone', 'contact_phone', 'phone_number', 'cellphone'],
                'business_domain': 'contact'
            },
            'address': {
                'type': 'VARCHAR(200)',
                'description': 'é‚®å¯„æˆ–è”ç³»åœ°å€',
                'generator': self._gen_address,
                'synonyms': ['addr', 'location', 'street_address', 'mailing_address', 'contact_address'],
                'business_domain': 'contact'
            },
            'category': {
                'type': 'VARCHAR(50)',
                'description': 'åˆ†ç±»æˆ–ç±»åˆ«ä»£ç ',
                'generator': self._gen_category,
                'synonyms': ['type', 'class', 'group', 'category_code', 'classification', 'kind'],
                'business_domain': 'product'
            },
            'quantity': {
                'type': 'DECIMAL(18,2)',
                'description': 'å•†å“æ•°é‡æˆ–åº“å­˜é‡',
                'generator': self._gen_quantity,
                'synonyms': ['qty', 'count', 'volume', 'units', 'amount', 'stock'],
                'business_domain': 'inventory'
            },
            'price': {
                'type': 'DECIMAL(20,4)',
                'description': 'å•†å“å•ä»·æˆ–ä»·æ ¼',
                'generator': self._gen_price,
                'synonyms': ['unit_price', 'cost', 'rate', 'price_amount', 'sale_price'],
                'business_domain': 'product'
            },
            'product_id': {
                'type': 'BIGINT',
                'description': 'å•†å“å”¯ä¸€æ ‡è¯†ç¬¦',
                'generator': self._gen_id,
                'synonyms': ['item_id', 'sku', 'product_code', 'goods_id', 'merchandise_id'],
                'business_domain': 'product'
            },
            'order_id': {
                'type': 'BIGINT',
                'description': 'è®¢å•æˆ–äº¤æ˜“å”¯ä¸€æ ‡è¯†',
                'generator': self._gen_id,
                'synonyms': ['txn_id', 'transaction_id', 'reference_id', 'invoice_id', 'deal_id'],
                'business_domain': 'trade'
            },
            'payment_method': {
                'type': 'VARCHAR(30)',
                'description': 'æ”¯ä»˜æ–¹å¼ç±»å‹',
                'generator': self._gen_payment_method,
                'synonyms': ['pay_method', 'payment_type', 'settlement_method', 'pay_type'],
                'business_domain': 'payment'
            },
            'discount': {
                'type': 'DECIMAL(10,4)',
                'description': 'æŠ˜æ‰£ç‡æˆ–ä¼˜æƒ é‡‘é¢',
                'generator': self._gen_discount,
                'synonyms': ['discount_rate', 'disc', 'promo', 'rebate', 'concession'],
                'business_domain': 'sales'
            },
            'create_time': {
                'type': 'TIMESTAMP',
                'description': 'è®°å½•åˆ›å»ºæ—¶é—´',
                'generator': self._gen_timestamp,
                'synonyms': ['created_at', 'create_time', 'insert_time', 'creation_time'],
                'business_domain': 'system'
            },
            'update_time': {
                'type': 'TIMESTAMP',
                'description': 'è®°å½•æœ€åæ›´æ–°æ—¶é—´',
                'generator': self._gen_timestamp,
                'synonyms': ['updated_at', 'update_time', 'modify_time', 'last_modified'],
                'business_domain': 'system'
            }
        }

        # ä¸šåŠ¡ä¸»é¢˜å®šä¹‰ï¼ˆåŒ…å«è¡¨æ³¨é‡Šå’Œä¸šåŠ¡åŸŸï¼‰
        self.themes = {
            'finance': {
                'core_fields': ['currency_code', 'exchange_rate', 'amount', 'account_id', 'date'],
                'optional_fields': ['status', 'region', 'user_id', 'order_id', 'create_time', 'update_time'],
                'description': 'é‡‘èäº¤æ˜“æµæ°´è¡¨ï¼Œè®°å½•è´§å¸å…‘æ¢å’Œèµ„é‡‘æµåŠ¨',
                'table_comment': 'é‡‘èç±»äº¤æ˜“æ ¸å¿ƒæ•°æ®è¡¨',
                'business_domain': 'finance'
            },
            'trade': {
                'core_fields': ['order_id', 'date', 'amount', 'status', 'region', 'currency_code'],
                'optional_fields': ['product_id', 'quantity', 'price', 'discount', 'user_id', 'payment_method'],
                'description': 'è´¸æ˜“è®¢å•ä¸»è¡¨ï¼Œè®°å½•å•†ä¸šäº¤æ˜“è®¢å•ä¿¡æ¯',
                'table_comment': 'è®¢å•äº¤æ˜“ä¸»æ•°æ®è¡¨',
                'business_domain': 'trade'
            },
            'user': {
                'core_fields': ['user_id', 'date', 'region', 'status', 'account_id'],
                'optional_fields': ['email', 'phone', 'address', 'category', 'create_time', 'update_time'],
                'description': 'ç”¨æˆ·æ³¨å†Œä¿¡æ¯è¡¨ï¼Œè®°å½•ç”¨æˆ·åŸºç¡€èµ„æ–™',
                'table_comment': 'ç”¨æˆ·ä¸»æ•°æ®è¡¨',
                'business_domain': 'crm'
            },
            'inventory': {
                'core_fields': ['product_id', 'quantity', 'date', 'status', 'region'],
                'optional_fields': ['price', 'category', 'account_id', 'order_id', 'discount'],
                'description': 'åº“å­˜ç®¡ç†è¡¨ï¼Œè®°å½•å•†å“åº“å­˜å˜åŠ¨',
                'table_comment': 'åº“å­˜äº‹åŠ¡è®°å½•è¡¨',
                'business_domain': 'supply_chain'
            },
            'payment': {
                'core_fields': ['order_id', 'amount', 'payment_method', 'date', 'account_id'],
                'optional_fields': ['currency_code', 'status', 'discount', 'user_id', 'region'],
                'description': 'æ”¯ä»˜äº¤æ˜“è®°å½•è¡¨',
                'table_comment': 'æ”¯ä»˜æµæ°´æ˜ç»†è¡¨',
                'business_domain': 'finance'
            },
            'customer': {
                'core_fields': ['user_id', 'email', 'phone', 'region', 'date'],
                'optional_fields': ['address', 'category', 'status', 'account_id', 'create_time'],
                'description': 'å®¢æˆ·è¯¦ç»†ä¿¡æ¯è¡¨',
                'table_comment': 'å®¢æˆ·ä¸»æ•°æ®è¡¨',
                'business_domain': 'crm'
            },
            'product': {
                'core_fields': ['product_id', 'category', 'price', 'status', 'create_time'],
                'optional_fields': ['quantity', 'discount', 'region', 'update_time'],
                'description': 'äº§å“åŸºç¡€ä¿¡æ¯è¡¨',
                'table_comment': 'äº§å“ä¸»æ•°æ®è¡¨',
                'business_domain': 'product'
            },
            'logistics': {
                'core_fields': ['order_id', 'user_id', 'date', 'region', 'status'],
                'optional_fields': ['address', 'quantity', 'amount', 'product_id', 'delivery_method'],
                'description': 'ç‰©æµé…é€ä¿¡æ¯è¡¨',
                'table_comment': 'ç‰©æµè·Ÿè¸ªè®°å½•è¡¨',
                'business_domain': 'supply_chain'
            },
        }

        # æ„å»ºåŒä¹‰è¯åå‘æ˜ å°„ä¸ä¸šåŠ¡åŸŸæ˜ å°„
        self.synonym_map = self._build_synonym_map()
        self.field_domain_map = self._build_field_domain_map()

    def _build_synonym_map(self) -> Dict[str, str]:
        """æ„å»ºåŒä¹‰è¯åå‘æ˜ å°„ï¼šsynonym -> canonical_name"""
        synonym_map = {}
        for field, info in self.field_templates.items():
            for synonym in info.get('synonyms', []):
                if synonym in synonym_map:
                    print(f"âš ï¸ åŒä¹‰è¯å†²çª: {synonym} æ˜ å°„åˆ°å¤šä¸ªå­—æ®µ")
                synonym_map[synonym] = field
        return synonym_map

    def _build_field_domain_map(self) -> Dict[str, str]:
        """æ„å»ºå­—æ®µä¸šåŠ¡åŸŸæ˜ å°„"""
        domain_map = {}
        for field, info in self.field_templates.items():
            domain_map[field] = info.get('business_domain', 'common')
        return domain_map

    # ========== æ•°æ®ç”Ÿæˆå™¨æ–¹æ³•ï¼ˆå¸¦åˆ†å¸ƒæ§åˆ¶ï¼‰ ==========
    def _gen_currency_code(self, n):
        """ç”Ÿæˆè´§å¸ä»£ç ï¼ˆä¿®å¤æ¦‚ç‡å’Œä¸ç­‰äº1çš„é”™è¯¯ï¼‰"""
        # åŸå§‹æƒé‡å’Œä¸º1.05ï¼Œéœ€å½’ä¸€åŒ–
        weights = np.array([0.4, 0.3, 0.15, 0.05, 0.05, 0.025, 0.025, 0.05])
        weights = weights / weights.sum()  # å½’ä¸€åŒ–ç¡®ä¿å’Œä¸º1.0
        return np.random.choice(['CNY', 'USD', 'EUR', 'JPY', 'GBP', 'HKD', 'AUD', 'CAD'], n, p=weights)
    def _gen_rate(self, n):
        """ç”Ÿæˆç¬¦åˆçœŸå®æ±‡ç‡åˆ†å¸ƒçš„æ•°æ®"""
        # ä¸»è¦æ±‡ç‡åŒºé—´ï¼š0.1-15.0ï¼Œä½†å¤§éƒ¨åˆ†åœ¨0.5-8.0ä¹‹é—´
        base_rates = np.random.uniform(0.5, 8.0, n)
        # æ·»åŠ å°‘æ•°æç«¯å€¼
        extreme_mask = np.random.random(n) < 0.1
        base_rates[extreme_mask] = np.random.uniform(0.1, 15.0, extreme_mask.sum())
        return base_rates.round(6)

    def _gen_date(self, n):
        """ç”Ÿæˆ2021-2024å¹´çš„å·¥ä½œæ—¥æ—¥æœŸ"""
        start_date = datetime(2021, 1, 1)
        end_date = datetime(2024, 12, 31)
        days = (end_date - start_date).days

        dates = []
        for _ in range(n):
            # è·³è¿‡å‘¨æœ«ï¼ˆç®€å•æ¨¡æ‹Ÿå·¥ä½œæ—¥ï¼‰
            while True:
                offset = random.randint(0, days)
                d = start_date + timedelta(days=offset)
                if d.weekday() < 5:  # å‘¨ä¸€åˆ°å‘¨äº”
                    dates.append(d)
                    break
        return dates

    def _gen_amount(self, n):
        """ç”Ÿæˆç¬¦åˆçœŸå®äº¤æ˜“åˆ†å¸ƒçš„é‡‘é¢ï¼ˆé•¿å°¾åˆ†å¸ƒï¼‰"""
        # 80%å°é¢äº¤æ˜“ï¼Œ20%å¤§é¢äº¤æ˜“
        mask = np.random.random(n) < 0.8
        amounts = np.zeros(n)
        amounts[mask] = np.random.uniform(100, 50000, mask.sum())  # å°é¢
        amounts[~mask] = np.random.uniform(50000, 2000000, (~mask).sum())  # å¤§é¢
        return amounts.round(2)

    def _gen_id(self, n):
        return np.random.randint(10000, 99999999, n, dtype=np.int64)

    def _gen_status(self, n):
        weights = [0.5, 0.2, 0.15, 0.1, 0.03, 0.02]  # activeå 50%
        return np.random.choice(['active', 'pending', 'closed', 'suspended', 'approved', 'rejected'], n, p=weights)

    def _gen_region(self, n):
        tier1_cities = ['åŒ—äº¬', 'ä¸Šæµ·', 'æ·±åœ³', 'å¹¿å·'] * 3  # æé«˜ä¸€çº¿åŸå¸‚æƒé‡
        tier2_cities = ['æ­å·', 'æˆéƒ½', 'æ­¦æ±‰', 'è¥¿å®‰', 'å—äº¬', 'é‡åº†', 'å¤©æ´¥', 'è‹å·', 'é’å²›', 'éƒ‘å·', 'å¤§è¿']
        all_cities = tier1_cities + tier2_cities
        return np.random.choice(all_cities, n)  # ä¿®å¤ï¼šnp.randomchoice -> np.random.choice

    def _gen_email(self, n):
        domains = ['gmail.com', 'qq.com', '163.com', 'outlook.com', 'sina.com', '126.com']
        # æ­£å¸¸é‚®ä»¶å 90%ï¼Œå¼‚å¸¸å 10%
        emails = []
        for i in range(n):
            if random.random() < 0.9:
                emails.append(f"user{random.randint(1, 999999)}@{random.choice(domains)}")
            else:
                # æ·»åŠ ä¸€äº›å¼‚å¸¸æ ¼å¼ç”¨äºæµ‹è¯•
                emails.append(f"test..user{random.randint(1, 999)}@{random.choice(domains)}")
        return emails

    def _gen_phone(self, n):
        prefixes = ['13', '15', '16', '17', '18', '19']
        return [f"{random.choice(prefixes)}{''.join(random.choices('0123456789', k=9))}" for _ in range(n)]

    def _gen_address(self, n):
        districts = ['æœé˜³åŒº', 'æµ·æ·€åŒº', 'ä¸œåŸåŒº', 'è¥¿åŸåŒº', 'å—å±±åŒº', 'ç¦ç”°åŒº', 'å¤©æ²³åŒº', 'é»„æµ¦åŒº',
                     'æ­¦ä¾¯åŒº', 'é”¦æ±ŸåŒº', 'æ±Ÿæ±‰åŒº', 'æ´ªå±±åŒº', 'ç§¦æ·®åŒº', 'ç„æ­¦åŒº', 'å’Œå¹³åŒº', 'å—å¼€åŒº']
        return [f"{random.choice(districts)}è¡—é“{random.randint(1, 200)}å·" for _ in range(n)]

    def _gen_category(self, n):
        weights = [0.3, 0.25, 0.2, 0.15, 0.07, 0.02, 0.01]  # Aç±»å æ¯”æœ€é«˜
        return np.random.choice(['Aç±»', 'Bç±»', 'Cç±»', 'Dç±»', 'Eç±»', 'Fç±»', 'Gç±»'], n, p=weights)

    def _gen_quantity(self, n):
        # åº“å­˜æ•°é‡ç¬¦åˆå¯¹æ•°æ­£æ€åˆ†å¸ƒ
        return np.random.lognormal(mean=5, sigma=2, size=n).astype(int) + 1

    def _gen_price(self, n):
        # ä»·æ ¼åˆ†å¸ƒï¼šä½ç«¯(10-1000), ä¸­ç«¯(1000-10000), é«˜ç«¯(10000-50000)
        segments = np.random.choice([1, 2, 3], n, p=[0.6, 0.3, 0.1])
        prices = np.zeros(n)
        prices[segments == 1] = np.random.uniform(10, 1000, (segments == 1).sum())
        prices[segments == 2] = np.random.uniform(1000, 10000, (segments == 2).sum())
        prices[segments == 3] = np.random.uniform(10000, 50000, (segments == 3).sum())
        return prices.round(4)

    def _gen_payment_method(self, n):
        weights = [0.3, 0.1, 0.35, 0.2, 0.03, 0.02]  # æ”¯ä»˜å®å’Œä¿¡ç”¨å¡å ä¸»å¯¼
        return np.random.choice(['ä¿¡ç”¨å¡', 'å€Ÿè®°å¡', 'æ”¯ä»˜å®', 'å¾®ä¿¡æ”¯ä»˜', 'é“¶è¡Œè½¬è´¦', 'ç°é‡‘'], n, p=weights)

    def _gen_discount(self, n):
        # 70%æ— æŠ˜æ‰£ï¼Œ20%å°æŠ˜æ‰£(0-0.3), 10%å¤§æŠ˜æ‰£(0.3-0.8)
        discount_type = np.random.choice([0, 1, 2], n, p=[0.7, 0.2, 0.1])
        discounts = np.zeros(n)
        discounts[discount_type == 1] = np.random.uniform(0.01, 0.3, (discount_type == 1).sum())
        discounts[discount_type == 2] = np.random.uniform(0.3, 0.8, (discount_type == 2).sum())
        return discounts.round(4)

    def _gen_timestamp(self, n):
        """ç”Ÿæˆæ—¶é—´æˆ³"""
        return [datetime.now() - timedelta(days=random.randint(0, 365),
                                           seconds=random.randint(0, 86400)) for _ in range(n)]

    def _get_field_generator(self, field_name: str):
        """æ ¹æ®å­—æ®µåè·å–ç”Ÿæˆå™¨ï¼ˆæ”¯æŒåŒä¹‰è¯ï¼‰"""
        if field_name in self.field_templates:
            return self.field_templates[field_name]['generator']

        canonical_name = self.synonym_map.get(field_name)
        if canonical_name:
            return self.field_templates[canonical_name]['generator']

        # è®°å½•æœªçŸ¥å­—æ®µå¹¶è¿”å›é»˜è®¤ç”Ÿæˆå™¨
        print(f"âš ï¸ è­¦å‘Šï¼šæœªçŸ¥å­—æ®µç±»å‹ '{field_name}'ï¼Œä½¿ç”¨é»˜è®¤ç”Ÿæˆå™¨")
        return lambda n: [f'default_{field_name}_{i}' for i in range(n)]

    def _gen_field_data(self, field_type: str, n: int):
        """æ™ºèƒ½å­—æ®µæ•°æ®ç”Ÿæˆï¼ˆå¸¦ç¼“å­˜ä¼˜åŒ–ï¼‰"""
        generator = self._get_field_generator(field_type)
        return generator(n)

    # ========== è¡¨åˆ›å»ºä¸ç®¡ç† ==========
    def create_table(self, table_name: str, fields: List[Dict], n_samples: int = None,
                     table_comment: str = "") -> bool:
        """
        åˆ›å»ºè¡¨å¹¶å¡«å……æ•°æ®ï¼ˆå¸¦äº‹åŠ¡ä¿æŠ¤ï¼‰

        Returns:
            bool: åˆ›å»ºæ˜¯å¦æˆåŠŸ
        """
        if n_samples is None:
            n_samples = self.sample_size

        conn = self._get_db_connection()
        cursor = conn.cursor()

        try:
            # æ„å»ºå­—æ®µå®šä¹‰ï¼ˆåŒ…å«æ³¨é‡Šï¼‰
            field_defs = []
            for f in fields:
                comment = f.get('comment', '')
                if comment:
                    # è½¬ä¹‰SQLæ³¨é‡Šä¸­çš„ç‰¹æ®Šå­—ç¬¦
                    escaped_comment = comment.replace("'", "''").replace("\\", "\\\\")
                    field_def = f"{f['name']} {f['type']} COMMENT '{escaped_comment}'"
                else:
                    field_def = f"{f['name']} {f['type']}"
                field_defs.append(field_def)

            # è¡¨æ³¨é‡Šå¤„ç†
            escaped_table_comment = ""
            if table_comment:
                escaped_table_comment = table_comment.replace("'", "''").replace("\\", "\\\\")

            table_comment_clause = f" COMMENT='{escaped_table_comment}'" if escaped_table_comment else ""

            # åˆ›å»ºè¡¨ï¼ˆå¸¦äº‹åŠ¡ï¼‰
            create_sql = f"""
                CREATE TABLE IF NOT EXISTS {table_name} (
                    id BIGINT AUTO_INCREMENT PRIMARY KEY,
                    {', '.join(field_defs)}
                ) {table_comment_clause}
            """

            cursor.execute(create_sql)

            # ç”Ÿæˆæ•°æ®
            data = {}
            for field in fields:
                col_data = self._gen_field_data(field['name'], n_samples)
                # ç¡®ä¿æ•°æ®é•¿åº¦ä¸€è‡´
                if len(col_data) != n_samples:
                    col_data = col_data[:n_samples] + [col_data[-1]] * (n_samples - len(col_data))
                data[field['name']] = col_data

            # è½¬æ¢ä¸ºDataFrameå¹¶å†™å…¥ï¼ˆä½¿ç”¨äº‹åŠ¡ï¼‰
            df = pd.DataFrame(data)

            # æ•°æ®ç±»å‹è½¬æ¢ä¼˜åŒ–
            for field in fields:
                if 'INT' in field['type']:
                    df[field['name']] = pd.to_numeric(df[field['name']], errors='coerce').fillna(0).astype(np.int64)
                elif 'DECIMAL' in field['type'] or 'FLOAT' in field['type']:
                    df[field['name']] = pd.to_numeric(df[field['name']], errors='coerce').fillna(0.0)

            # å†™å…¥æ•°æ®åº“ï¼ˆæ›¿æ¢æ¨¡å¼ï¼‰
            df.to_sql(table_name, self.engine, if_exists='replace', index=False, chunksize=5000)

            conn.commit()

            # è®°å½•å…ƒæ•°æ®
            self.generation_metadata['tables_created'].append({
                'name': table_name,
                'fields': len(fields),
                'rows': n_samples,
                'comment': table_comment[:50]
            })

            for f in fields:
                self.generation_metadata['field_coverage'][table_name.split('_')[0]].add(f['name'])

            print(f"âœ… åˆ›å»ºè¡¨ {table_name}: {len(fields)}ä¸ªå­—æ®µ, {n_samples}æ¡è®°å½•")
            return True

        except mysql.connector.Error as e:
            conn.rollback()
            print(f"âŒ åˆ›å»ºè¡¨ {table_name} å¤±è´¥: {e}")
            return False
        finally:
            conn.close()

    def generate_theme_table(self, theme_name: str, table_index: int, variation_type: str = 'base') -> Tuple[
        str, List[Dict], str]:
        """
        ç”Ÿæˆä¸»é¢˜è¡¨ï¼ˆæ”¯æŒå¤šç§å˜ä½“ï¼Œå¸¦æ™ºèƒ½ç›¸ä¼¼åº¦é¢„è®¾ï¼‰

        Returns:
            (è¡¨å, å­—æ®µå®šä¹‰, è¡¨æ³¨é‡Š)
        """
        theme = self.themes[theme_name]

        # åŸºç¡€å­—æ®µ
        core_fields = theme['core_fields'].copy()
        optional_fields = theme['optional_fields'].copy()

        # å˜ä½“å¤„ç†é€»è¾‘ï¼ˆå¸¦åˆç†æ€§æ§åˆ¶ï¼‰
        synonym_replacements = []  # ä¸´æ—¶å­˜å‚¨æ›¿æ¢è®°å½•
        if variation_type == 'synonym':
            # åŒä¹‰å­—æ®µæ›¿æ¢ï¼ˆç¡®ä¿è‡³å°‘æ›¿æ¢30%ä½†ä¸è¶…60%ï¼‰
            min_replace = max(1, len(core_fields) // 3)
            max_replace = max(2, len(core_fields) * 2 // 3)
            num_replace = random.randint(min_replace, max_replace)
            replace_indices = random.sample(range(len(core_fields)), min(num_replace, len(core_fields)))

            for idx in replace_indices:
                original_field = core_fields[idx]
                if original_field in self.field_templates:
                    synonyms = self.field_templates[original_field]['synonyms']
                    if synonyms:
                        # é¿å…æ›¿æ¢ä¸ºä¸šåŠ¡åŸŸå·®å¼‚è¿‡å¤§çš„åŒä¹‰è¯
                        chosen_synonym = random.choice(synonyms)
                        # ä¸´æ—¶è®°å½•æ›¿æ¢å…³ç³»ï¼ˆç­‰å¾…table_nameç”Ÿæˆåå†å­˜å‚¨ï¼‰
                        synonym_replacements.append((original_field, chosen_synonym))
                        core_fields[idx] = chosen_synonym

        elif variation_type == 'extra':
            # æ·»åŠ é¢å¤–å­—æ®µï¼ˆç¡®ä¿å­—æ®µå­˜åœ¨ä¸”ä¸šåŠ¡ç›¸å…³ï¼‰
            valid_optional = [f for f in optional_fields if self._field_exists(f)]
            if valid_optional:
                # ä¸šåŠ¡åŸŸåŒ¹é…ä¼˜å…ˆ
                theme_domain = theme.get('business_domain')
                domain_matching = [f for f in valid_optional if self.field_domain_map.get(f) == theme_domain]
                if domain_matching:
                    valid_optional = domain_matching + valid_optional

                num_extra = random.randint(2, min(4, len(valid_optional)))
                extra_fields = random.sample(valid_optional, num_extra)
                core_fields.extend(extra_fields)

        elif variation_type == 'missing':
            # å­—æ®µç¼ºå¤±ï¼ˆä¿ç•™è‡³å°‘60%æ ¸å¿ƒå­—æ®µï¼‰
            min_keep = max(3, len(core_fields) * 3 // 5)
            if len(core_fields) > min_keep:
                num_missing = random.randint(1, len(core_fields) - min_keep)
                keep_indices = random.sample(range(len(core_fields)), len(core_fields) - num_missing)
                core_fields = [core_fields[i] for i in sorted(keep_indices)]

        # éšæœºæ‰“ä¹±å­—æ®µé¡ºåºï¼ˆæ¨¡æ‹ŸçœŸå®schemaå·®å¼‚ï¼‰
        random.shuffle(core_fields)

        # æ„å»ºå­—æ®µå®šä¹‰ï¼ˆåŒ…å«æ³¨é‡Šå’Œä¸šåŠ¡åŸŸï¼‰
        fields = []
        for field_name in core_fields:
            canonical_name = self.synonym_map.get(field_name, field_name)

            # éªŒè¯å­—æ®µå­˜åœ¨
            if not self._field_exists(canonical_name):
                print(f"âš ï¸ è·³è¿‡ä¸å­˜åœ¨çš„å­—æ®µ: {field_name} -> {canonical_name}")
                continue

            field_info = self.field_templates[canonical_name]
            fields.append({
                'name': field_name,
                'type': field_info['type'],
                'comment': field_info['description'],
                'domain': field_info.get('business_domain', 'common')
            })

        # è¡¨åå’Œè¡¨æ³¨é‡Š
        table_name = f"{theme_name}_{table_index}_{variation_type}"
        table_comment = theme.get('table_comment', f'{theme["description"]} - {variation_type}å˜ä½“')

        # ===== å…³é”®ä¿®å¤ï¼šåœ¨table_nameå®šä¹‰åè®°å½•å…ƒæ•°æ® =====
        if synonym_replacements:
            self.generation_metadata['synonym_replacements'][table_name] = synonym_replacements

        return table_name, fields, table_comment

    def _field_exists(self, field_name: str) -> bool:
        """æ£€æŸ¥å­—æ®µæ˜¯å¦åœ¨æ¨¡æ¿ä¸­å®šä¹‰"""
        return field_name in self.field_templates

    # ========== å¤§è§„æ¨¡è¡¨ç”Ÿæˆï¼ˆä¸»æµç¨‹ï¼‰ ==========
    def generate_massive_tables(self) -> List[str]:
        """å¤§è§„æ¨¡è¡¨ç”Ÿæˆï¼šç”Ÿæˆå¤šæ ·åŒ–çš„è¡¨ï¼ˆå¸¦ç¡¬æ¡ˆä¾‹æ³¨å†Œï¼‰"""
        print("\n" + "=" * 60)
        print("å¼€å§‹å¤§è§„æ¨¡è¡¨ç”Ÿæˆ...")
        print("=" * 60)

        # æ¸…ç©ºæ—§æ•°æ®ï¼ˆå¸¦ç¡®è®¤ï¼‰
        self._reset_database()

        tables = []
        theme_names = list(self.themes.keys())

        print(f"\nğŸ“Š ç”Ÿæˆ {len(theme_names)} ä¸ªä¸»é¢˜ï¼Œæ¯ä¸ªä¸»é¢˜ {self.base_tables_per_theme} ä¸ªåŸºç¡€è¡¨")

        for theme_name in theme_names:
            theme_info = self.themes[theme_name]
            print(f"\nã€{theme_name}ã€‘ {theme_info['description']}")

            # åŸºç¡€å˜ä½“
            print("  â”œâ”€ åŸºç¡€è¡¨...")
            for i in range(self.base_tables_per_theme):
                table_name, fields, comment = self.generate_theme_table(theme_name, i, 'base')
                if self.create_table(table_name, fields, table_comment=comment):
                    tables.append(table_name)

            # åŒä¹‰å­—æ®µå˜ä½“
            num_synonym = int(self.base_tables_per_theme * self.synonym_prob)
            if num_synonym > 0:
                print("  â”œâ”€ åŒä¹‰å­—æ®µå˜ä½“è¡¨...")
                for i in range(num_synonym):
                    table_name, fields, comment = self.generate_theme_table(theme_name, i, 'synonym')
                    if self.create_table(table_name, fields, table_comment=comment):
                        tables.append(table_name)

            # é¢å¤–å­—æ®µå˜ä½“
            num_extra = int(self.base_tables_per_theme * self.extra_field_prob)
            if num_extra > 0:
                print("  â”œâ”€ é¢å¤–å­—æ®µå˜ä½“è¡¨...")
                for i in range(num_extra):
                    table_name, fields, comment = self.generate_theme_table(theme_name, i, 'extra')
                    if self.create_table(table_name, fields, table_comment=comment):
                        tables.append(table_name)

            # å­—æ®µç¼ºå¤±å˜ä½“
            num_missing = int(self.base_tables_per_theme * self.missing_field_prob)
            if num_missing > 0:
                print("  â””â”€ å­—æ®µç¼ºå¤±å˜ä½“è¡¨...")
                for i in range(num_missing):
                    table_name, fields, comment = self.generate_theme_table(theme_name, i, 'missing')
                    if self.create_table(table_name, fields, table_comment=comment):
                        tables.append(table_name)

        # ===== ç¡¬æ¡ˆä¾‹è¡¨ç”Ÿæˆï¼ˆå…³é”®ä¿®å¤ï¼šå¿…é¡»æ³¨å†Œåˆ°tablesåˆ—è¡¨ï¼‰ =====
        hard_tables = self.generate_hard_case_tables()
        tables.extend(hard_tables)

        # ========== æ•°æ®è´¨é‡è‡ªæ£€ ==========
        self._validate_generation(tables)

        print(f"\nâœ… è¡¨ç”Ÿæˆå®Œæˆï¼æ€»è®¡ {len(tables)} ä¸ªè¡¨")
        return tables

    def _reset_database(self):
        """å®‰å…¨é‡ç½®æ•°æ®åº“"""
        print(f"ğŸ—‘ï¸  æ¸…ç©ºæ—§æ•°æ®...")
        conn = self._get_db_connection()
        cursor = conn.cursor()

        try:
            cursor.execute("SHOW TABLES")
            tables = cursor.fetchall()
            if tables:
                for table in tables:
                    cursor.execute(f"DROP TABLE IF EXISTS {table[0]}")
                conn.commit()
        except mysql.connector.Error as e:
            print(f"âš ï¸  æ¸…ç©ºè¡¨æ—¶å‡ºé”™: {e}")
        finally:
            conn.close()

    def generate_hard_case_tables(self) -> List[str]:
        """
        ç”Ÿæˆä¸“é¡¹ç¡¬æ¡ˆä¾‹è¡¨ï¼ˆå¸¦æ­£ç¡®ç›¸ä¼¼åº¦æ ‡ç­¾ï¼‰
        è¿”å›ï¼šç¡¬æ¡ˆä¾‹è¡¨ååˆ—è¡¨ï¼ˆç¡®ä¿è¢«æ ‡æ³¨ï¼‰
        """
        print("\n" + "-" * 40)
        print("ç”Ÿæˆç¡¬æ¡ˆä¾‹è¡¨ï¼ˆå›°éš¾æ ·æœ¬ï¼‰...")

        hard_tables = []

        # æ¡ˆä¾‹1ï¼šåŒä¹‰å­—æ®µè¡¨å¯¹ï¼ˆåº”æé«˜ç›¸ä¼¼åº¦ï¼š0.92ï¼‰
        base_fields = [
            {'name': 'currency_code', 'type': 'VARCHAR(10)', 'comment': 'è´§å¸ä»£ç '},
            {'name': 'exchange_rate', 'type': 'DECIMAL(20,6)', 'comment': 'æ±‡ç‡'},
            {'name': 'date', 'type': 'DATE', 'comment': 'äº¤æ˜“æ—¥æœŸ'},
            {'name': 'amount', 'type': 'DECIMAL(20,2)', 'comment': 'é‡‘é¢'},
        ]
        if self.create_table("hard_case_base", base_fields, n_samples=500,
                             table_comment='ç¡¬æ¡ˆä¾‹ï¼šåŸºç¡€é‡‘èè¡¨ï¼ˆåŸºå‡†ï¼‰'):
            hard_tables.append("hard_case_base")

        synonym_fields = [
            {'name': 'fx_code', 'type': 'VARCHAR(10)', 'comment': 'è´§å¸ä»£ç ï¼ˆåŒä¹‰ï¼‰'},
            {'name': 'fx_rate', 'type': 'DECIMAL(20,6)', 'comment': 'æ±‡ç‡ï¼ˆåŒä¹‰ï¼‰'},
            {'name': 'value_date', 'type': 'DATE', 'comment': 'ç”Ÿæ•ˆæ—¥æœŸï¼ˆåŒä¹‰ï¼‰'},
            {'name': 'tx_amount', 'type': 'DECIMAL(20,2)', 'comment': 'äº¤æ˜“é‡‘é¢ï¼ˆåŒä¹‰ï¼‰'},
        ]
        if self.create_table("hard_case_synonym", synonym_fields, n_samples=500,
                             table_comment='ç¡¬æ¡ˆä¾‹ï¼šåŒä¹‰å­—æ®µè¡¨ï¼ˆæµ‹è¯•åŒä¹‰è¯è¯†åˆ«ï¼‰'):
            hard_tables.append("hard_case_synonym")

        # æ¡ˆä¾‹2ï¼šé¢å¤–å­—æ®µè¡¨å¯¹ï¼ˆåº”ä¸­é«˜ç›¸ä¼¼åº¦ï¼š0.75ï¼Œè€Œé1.0ï¼‰
        extra_fields = base_fields + [
            {'name': 'extra_info', 'type': 'VARCHAR(200)', 'comment': 'é¢å¤–ä¿¡æ¯'},
            {'name': 'created_by', 'type': 'VARCHAR(50)', 'comment': 'åˆ›å»ºäºº'},
            {'name': 'last_updated', 'type': 'TIMESTAMP', 'comment': 'æœ€åæ›´æ–°æ—¶é—´'},
        ]
        if self.create_table("hard_case_extra", extra_fields, n_samples=500,
                             table_comment='ç¡¬æ¡ˆä¾‹ï¼šé¢å¤–å­—æ®µè¡¨ï¼ˆæµ‹è¯•å†—ä½™å®¹å¿ï¼Œç›®æ ‡ç›¸ä¼¼åº¦0.75ï¼‰'):
            hard_tables.append("hard_case_extra")

        # æ¡ˆä¾‹3ï¼šéƒ¨åˆ†é‡å è¡¨å¯¹ï¼ˆåº”ä¸­ç­‰ç›¸ä¼¼åº¦ï¼š0.65ï¼‰
        partial_fields = [
            {'name': 'currency_code', 'type': 'VARCHAR(10)', 'comment': 'è´§å¸ä»£ç '},
            {'name': 'date', 'type': 'DATE', 'comment': 'äº¤æ˜“æ—¥æœŸ'},
            {'name': 'amount', 'type': 'DECIMAL(20,2)', 'comment': 'é‡‘é¢'},
            {'name': 'user_id', 'type': 'BIGINT', 'comment': 'ç”¨æˆ·ID'},
            {'name': 'status', 'type': 'VARCHAR(20)', 'comment': 'çŠ¶æ€'},
            {'name': 'region', 'type': 'VARCHAR(50)', 'comment': 'åŒºåŸŸ'},
        ]
        if self.create_table("hard_case_partial", partial_fields, n_samples=500,
                             table_comment='ç¡¬æ¡ˆä¾‹ï¼šéƒ¨åˆ†é‡å è¡¨ï¼ˆæµ‹è¯•éƒ¨åˆ†åŒ¹é…ï¼Œç›®æ ‡ç›¸ä¼¼åº¦0.65ï¼‰'):
            hard_tables.append("hard_case_partial")

        # æ¡ˆä¾‹4ï¼šç»“æ„ç›¸ä¼¼ä½†ä¸šåŠ¡åŸŸä¸åŒï¼ˆåº”ä½ç›¸ä¼¼åº¦ï¼š0.35ï¼‰
        diff_domain_fields = [
            {'name': 'user_id', 'type': 'BIGINT', 'comment': 'ç”¨æˆ·ID'},
            {'name': 'status', 'type': 'VARCHAR(20)', 'comment': 'çŠ¶æ€'},
            {'name': 'date', 'type': 'DATE', 'comment': 'æ—¥æœŸ'},
            {'name': 'account_id', 'type': 'BIGINT', 'comment': 'è´¦æˆ·ID'},
        ]
        if self.create_table("hard_case_different", diff_domain_fields, n_samples=500,
                             table_comment='ç¡¬æ¡ˆä¾‹ï¼šä¸åŒä¸šåŠ¡åŸŸï¼ˆæµ‹è¯•è¯­ä¹‰åŒºåˆ†ï¼Œç›®æ ‡ç›¸ä¼¼åº¦0.35ï¼‰'):
            hard_tables.append("hard_case_different")

        print(f"âœ… ç¡¬æ¡ˆä¾‹è¡¨ç”Ÿæˆå®Œæˆ: {len(hard_tables)}ä¸ªè¡¨")
        return hard_tables

    def _validate_generation(self, table_list: List[str]):
        """ç”Ÿæˆåæ•°æ®è´¨é‡éªŒè¯"""
        print("\n" + "-" * 40)
        print("ğŸ” æ•°æ®è´¨é‡è‡ªæ£€...")

        conn = self._get_db_connection()
        cursor = conn.cursor()

        issues = []

        try:
            # æ£€æŸ¥1ï¼šæ‰€æœ‰è¡¨æ˜¯å¦å­˜åœ¨
            cursor.execute("SHOW TABLES")
            existing_tables = {row[0] for row in cursor.fetchall()}
            missing_tables = set(table_list) - existing_tables
            if missing_tables:
                issues.append(f"è¡¨åˆ›å»ºåç¼ºå¤±: {missing_tables}")

            # æ£€æŸ¥2ï¼šæ¯å¼ è¡¨æ˜¯å¦æœ‰æ•°æ®
            for table in table_list[:10]:  # æŠ½æŸ¥å‰10å¼ è¡¨
                cursor.execute(f"SELECT COUNT(*) FROM {table}")
                count = cursor.fetchone()[0]
                if count == 0:
                    issues.append(f"è¡¨ {table} æ— æ•°æ®")

            # æ£€æŸ¥3ï¼šå­—æ®µæ³¨é‡Šå®Œæ•´æ€§
            cursor.execute("""
                SELECT table_name, column_name, column_comment 
                FROM information_schema.COLUMNS 
                WHERE table_schema = %s AND column_comment = ''
            """, (self.mysql_database,))
            no_comment_cols = cursor.fetchall()
            if no_comment_cols:
                issues.append(f"æœ‰ {len(no_comment_cols)} ä¸ªå­—æ®µç¼ºå°‘æ³¨é‡Š")

        finally:
            conn.close()

        if issues:
            print("âš ï¸  å‘ç°ä»¥ä¸‹é—®é¢˜:")
            for issue in issues:
                print(f"   - {issue}")
        else:
            print("âœ… æ•°æ®è´¨é‡æ£€æŸ¥é€šè¿‡")

        # æ‰“å°ç”Ÿæˆç»Ÿè®¡
        print("\nğŸ“ˆ ç”Ÿæˆç»Ÿè®¡:")
        print(f"   - æ€»è¡¨æ•°: {len(table_list)}")
        print(f"   - å­—æ®µè¦†ç›–ç‡: {len(self.generation_metadata['field_coverage'])}ä¸ªä¸šåŠ¡åŸŸ")
        total_fields = sum(len(cols) for cols in self.generation_metadata['field_coverage'].values())
        print(f"   - æ€»å­—æ®µæ•°: {total_fields}")
        print(f"   - åŒä¹‰æ›¿æ¢è®°å½•: {sum(len(v) for v in self.generation_metadata['synonym_replacements'].values())}")

    # ========== ç›¸ä¼¼åº¦è®¡ç®—ï¼ˆæ ¸å¿ƒä¿®å¤ï¼‰ ==========
    def _calculate_field_overlap(self, fields_a: Set[str], fields_b: Set[str]) -> Dict:
        """
        è®¡ç®—å­—æ®µé‡å åº¦ï¼ˆå¸¦åŒä¹‰è¯å½’ä¸€åŒ–å’Œä¸šåŠ¡åŸŸæƒé‡ï¼‰

        Returns:
            Dict: åŒ…å«overlap, overlap_weighted, shared_fieldsç­‰ä¿¡æ¯
        """
        # å½’ä¸€åŒ–åˆ°æ ‡å‡†å­—æ®µå
        canonical_a = {self.synonym_map.get(f, f) for f in fields_a}
        canonical_b = {self.synonym_map.get(f, f) for f in fields_b}

        # åŸºç¡€é‡å åº¦
        intersection = len(canonical_a & canonical_b)
        union = len(canonical_a | canonical_b)
        overlap = intersection / union if union > 0 else 0.0

        # ä¸šåŠ¡åŸŸåŠ æƒï¼ˆåŒåŸŸå­—æ®µæƒé‡æ›´é«˜ï¼‰
        shared_fields = canonical_a & canonical_b
        domain_weights = []
        for field in shared_fields:
            domain_a = self.field_domain_map.get(field, 'common')
            domain_b = self.field_domain_map.get(field, 'common')
            # åŒåŸŸæƒé‡1.2ï¼Œå¼‚åŸŸæƒé‡0.8
            weight = 1.2 if domain_a == domain_b else 0.8
            domain_weights.append(weight)

        weighted_overlap = overlap
        if domain_weights:
            avg_weight = sum(domain_weights) / len(domain_weights)
            weighted_overlap = min(1.0, overlap * avg_weight)

        return {
            'overlap': overlap,
            'weighted_overlap': weighted_overlap,
            'intersection': shared_fields,
            'intersection_count': intersection,
            'union_count': union
        }

    def _calculate_semantic_similarity(self, table_a: Dict, table_b: Dict) -> float:
        """
        è®¡ç®—è¯­ä¹‰ç›¸ä¼¼åº¦ï¼ˆåŸºäºä¸šåŠ¡ä¸»é¢˜å’Œå…³é”®å­—æ®µï¼‰
        ä¿®å¤ï¼šè¿”å›æ›´åˆç†çš„åŠ æˆå€¼ï¼Œé¿å…è¿‡åº¦æƒ©ç½š
        """
        a_theme = table_a.get('theme', '')
        b_theme = table_b.get('theme', '')

        semantic_score = 0.0

        # ä¸»é¢˜ç›¸åŒï¼ˆé«˜åŠ æˆï¼‰
        if a_theme and b_theme and a_theme == b_theme:
            semantic_score += 0.15  # ä¿®å¤ï¼šä»0.7é™è‡³0.15ï¼Œé¿å…è¿‡åº¦åŠ æˆ

        # å…³é”®ä¸šåŠ¡å­—æ®µé‡å ï¼ˆä¸­ç­‰åŠ æˆï¼‰
        key_fields = {'user_id', 'account_id', 'order_id', 'product_id'}
        a_keys = key_fields & set(table_a['fields'])
        b_keys = key_fields & set(table_b['fields'])

        if a_keys and b_keys:
            shared_keys = a_keys & b_keys
            if len(shared_keys) > 0:
                # å…±äº«å…³é”®å­—æ®µè¶Šå¤šï¼ŒåŠ æˆè¶Šé«˜ï¼ˆæœ€é«˜0.1ï¼‰
                semantic_score += min(0.1, len(shared_keys) * 0.03)

        return semantic_score

    def _calculate_variation_penalty(self, table_a: Dict, table_b: Dict) -> float:
        """
        è®¡ç®—å˜ä½“ç±»å‹æƒ©ç½šï¼ˆé¢å¤–å­—æ®µä¸åº”è¿‡åº¦æƒ©ç½šï¼‰
        ä¿®å¤ï¼šæƒ©ç½šå€¼ä»-0.05ä¼˜åŒ–ä¸º-0.02ï¼Œé¿å…ç›¸ä¼¼åº¦è™šä½
        """
        penalty = 0.0

        # é¢å¤–å­—æ®µæƒ©ç½šï¼ˆè½»å¾®ï¼‰
        if ('extra' in table_a['name'] or 'extra' in table_b['name']):
            # æ£€æŸ¥é¢å¤–å­—æ®µæ•°é‡
            extra_count = abs(len(table_a['fields']) - len(table_b['fields']))
            penalty -= min(0.02, extra_count * 0.005)  # æœ€å¤šé™0.02

        # ç¼ºå¤±å­—æ®µæƒ©ç½šï¼ˆè½»å¾®ï¼‰
        if ('missing' in table_a['name'] or 'missing' in table_b['name']):
            missing_ratio = 1 - len(table_a['fields'] & table_b['fields']) / len(table_a['fields'] | table_b['fields'])
            penalty -= min(0.03, missing_ratio * 0.05)  # æœ€å¤šé™0.03

        return penalty

    def _calculate_structural_similarity(self, table_a: Dict, table_b: Dict) -> float:
        """
        è®¡ç®—ç»“æ„ç›¸ä¼¼åº¦ï¼ˆå­—æ®µå+ç±»å‹+é¡ºåºï¼‰
        """
        fields_a = list(table_a['fields'])
        fields_b = list(table_b['fields'])

        # å­—æ®µé¡ºåºç›¸ä¼¼åº¦ï¼ˆæœ€é•¿å…¬å…±å­åºåˆ—ï¼‰
        from difflib import SequenceMatcher
        order_sim = SequenceMatcher(None, fields_a, fields_b).ratio()

        # ç±»å‹ç›¸ä¼¼åº¦ï¼ˆåŸºäºæ ‡å‡†å­—æ®µåï¼‰
        canonical_a = [self.synonym_map.get(f, f) for f in fields_a]
        canonical_b = [self.synonym_map.get(f, f) for f in fields_b]

        # è·å–å­—æ®µç±»å‹
        types_a = [self.field_templates.get(f, {}).get('type', 'VARCHAR(50)') for f in canonical_a]
        types_b = [self.field_templates.get(f, {}).get('type', 'VARCHAR(50)') for f in canonical_b]

        # è®¡ç®—ç±»å‹åŒ¹é…åº¦
        type_matches = sum(1 for a, b in zip(types_a, types_b) if a.split('(')[0] == b.split('(')[0])
        type_sim = type_matches / max(len(types_a), len(types_b), 1)

        # ç»¼åˆç»“æ„ç›¸ä¼¼åº¦
        return order_sim * 0.3 + type_sim * 0.7

    # ========== å¢å¼ºæ ‡æ³¨ç”Ÿæˆï¼ˆæ ¸å¿ƒä¿®å¤ï¼‰ ==========
    def generate_enhanced_annotations(self, table_list: List[str]) -> List[Dict]:
        """
        ç”Ÿæˆå¢å¼ºæ ‡æ³¨ï¼ˆå¸¦ç¡¬æ¡ˆä¾‹æ˜¾å¼æ³¨å†Œå’Œåˆç†ç›¸ä¼¼åº¦ï¼‰
        ä¿®å¤ï¼š
        1. ç¡¬æ¡ˆä¾‹è¡¨å¿…é¡»å­˜åœ¨äºtable_info_cache
        2. ç›¸ä¼¼åº¦æ ‡ç­¾åæ˜ çœŸå®è¯­ä¹‰å…³ç³»
        3. æ ‡ç­¾å¹³æ»‘æ›´ä¿å®ˆ
        """
        print("\n" + "-" * 40)
        print("å¼€å§‹ç”Ÿæˆå¢å¼ºæ ‡æ³¨...")

        annotations = []
        table_info_cache = {}

        conn = self._get_db_connection()
        cursor = conn.cursor()

        try:
            # åŠ è½½æ‰€æœ‰è¡¨ä¿¡æ¯
            for table_name in table_list:
                cursor.execute(f"SHOW COLUMNS FROM {table_name}")
                columns = cursor.fetchall()
                fields = {row[0] for row in columns}  # row[0] æ˜¯å­—æ®µå

                # è·å–è¡¨æ³¨é‡Š
                cursor.execute(
                    "SELECT table_comment FROM information_schema.TABLES "
                    "WHERE table_schema = %s AND table_name = %s",
                    (self.mysql_database, table_name)
                )
                table_comment_result = cursor.fetchone()
                table_comment = table_comment_result[0] if table_comment_result else ""

                # ===== ä¿®å¤ï¼šæ·»åŠ  'name' é”® =====
                table_info_cache[table_name] = {
                    'name': table_name,  # <-- æ·»åŠ è¿™ä¸€è¡Œ
                    'fields': fields,
                    'theme': table_name.split('_')[0],
                    'comment': table_comment
                }

        finally:
            conn.close()

        # ç”Ÿæˆæ‰€æœ‰è¡¨å¯¹ï¼ˆå¸¦è¿›åº¦æ˜¾ç¤ºï¼‰
        table_pairs = list(itertools.combinations(table_list, 2))
        print(f"   è®¡ç®— {len(table_pairs)} ä¸ªè¡¨å¯¹çš„ç›¸ä¼¼åº¦...")

        for idx, (table_a, table_b) in enumerate(table_pairs):
            if idx % 100 == 0:
                print(f"   è¿›åº¦: {idx}/{len(table_pairs)}")

            info_a = table_info_cache[table_a]
            info_b = table_info_cache[table_b]

            # åŸºç¡€å­—æ®µé‡å åº¦ï¼ˆå¸¦åŠ æƒï¼‰
            overlap_info = self._calculate_field_overlap(info_a['fields'], info_b['fields'])
            base_sim = overlap_info['weighted_overlap']

            # è¯­ä¹‰ç›¸ä¼¼åº¦ï¼ˆè½»å¾®åŠ æˆï¼‰
            semantic_bonus = self._calculate_semantic_similarity(info_a, info_b)

            # ç»“æ„ç›¸ä¼¼åº¦ï¼ˆé¢å¤–åŠ æˆï¼‰
            struct_bonus = self._calculate_structural_similarity(info_a, info_b) * 0.05

            # å˜ä½“ç±»å‹æƒ©ç½šï¼ˆè½»å¾®ï¼‰
            variation_penalty = self._calculate_variation_penalty(info_a, info_b)

            # åŒä¹‰å­—æ®µåŠ æˆï¼ˆä»…å½“åŸºç¡€ç›¸ä¼¼åº¦å·²è¾ƒé«˜ï¼‰
            synonym_bonus = 0.0
            if ('synonym' in table_a or 'synonym' in table_b) and base_sim > 0.6:
                synonym_bonus = 0.08  # è½»å¾®åŠ æˆï¼Œé¿å…è™šé«˜

            # ç»¼åˆè®¡ç®—å¹¶å½’ä¸€åŒ–
            similarity = base_sim + semantic_bonus + struct_bonus + synonym_bonus + variation_penalty
            similarity = max(0.0, min(1.0, similarity))

            # è¯†åˆ«å›°éš¾æ ·æœ¬ï¼ˆç›¸ä¼¼åº¦åœ¨æ¨¡ç³ŠåŒºé—´ï¼‰
            is_hard = self.hard_min_threshold <= similarity <= self.hard_max_threshold

            annotations.append({
                'table_a': table_a,
                'table_b': table_b,
                'similarity': round(similarity, 3),
                'base_overlap': round(overlap_info['overlap'], 3),
                'weighted_overlap': round(overlap_info['weighted_overlap'], 3),
                'is_hard': is_hard,
                'theme_a': info_a['theme'],
                'theme_b': info_b['theme'],
                'shared_fields': list(overlap_info['intersection']),
                'calc_details': {
                    'semantic_bonus': round(semantic_bonus, 3),
                    'struct_bonus': round(struct_bonus, 3),
                    'variation_penalty': round(variation_penalty, 3),
                    'synonym_bonus': round(synonym_bonus, 3)
                }
            })

        # ===== ç¡¬æ¡ˆä¾‹æ˜¾å¼æ³¨å†Œï¼ˆå…³é”®ä¿®å¤ï¼šç¡®ä¿åœ¨table_info_cacheä¸­ï¼‰ =====
        hard_cases = []

        # åŸºç¡€-åŒä¹‰ï¼ˆæé«˜ç›¸ä¼¼åº¦ï¼š0.92ï¼‰
        if 'hard_case_base' in table_info_cache and 'hard_case_synonym' in table_info_cache:
            hard_cases.append({
                'table_a': 'hard_case_base',
                'table_b': 'hard_case_synonym',
                'similarity': 0.92,
                'base_overlap': 1.0,
                'weighted_overlap': 1.0,
                'is_hard': False,
                'theme_a': 'hard_case',
                'theme_b': 'hard_case',
                'shared_fields': ['currency_code', 'exchange_rate', 'date', 'amount'],
                'note': 'åŒä¹‰å­—æ®µåº”æé«˜ç›¸ä¼¼',
                'calc_details': {
                    'semantic_bonus': 0.0,
                    'struct_bonus': 0.0,
                    'variation_penalty': 0.0,
                    'synonym_bonus': 0.0
                }
            })

        # åŸºç¡€-é¢å¤–ï¼ˆä¸­é«˜ç›¸ä¼¼åº¦ï¼š0.75ï¼‰
        if 'hard_case_base' in table_info_cache and 'hard_case_extra' in table_info_cache:
            hard_cases.append({
                'table_a': 'hard_case_base',
                'table_b': 'hard_case_extra',
                'similarity': 0.75,  # ä¿®å¤ï¼šä»0.85é™è‡³0.75ï¼Œåæ˜ é¢å¤–å­—æ®µçš„çœŸå®å½±å“
                'base_overlap': 0.57,  # 4/7å­—æ®µå…±äº«
                'weighted_overlap': 0.57,
                'is_hard': True,  # è¿™æ˜¯å›°éš¾æ ·æœ¬
                'theme_a': 'hard_case',
                'theme_b': 'hard_case',
                'shared_fields': ['currency_code', 'exchange_rate', 'date', 'amount'],
                'note': 'é¢å¤–å­—æ®µä¸åº”è¿‡åº¦æƒ©ç½š',
                'calc_details': {
                    'semantic_bonus': 0.0,
                    'struct_bonus': 0.03,
                    'variation_penalty': -0.02,  # è½»å¾®æƒ©ç½š
                    'synonym_bonus': 0.0
                }
            })

        # åŸºç¡€-éƒ¨åˆ†é‡å ï¼ˆä¸­ç­‰ç›¸ä¼¼åº¦ï¼š0.65ï¼‰
        if 'hard_case_base' in table_info_cache and 'hard_case_partial' in table_info_cache:
            hard_cases.append({
                'table_a': 'hard_case_base',
                'table_b': 'hard_case_partial',
                'similarity': 0.65,  # ä¿®å¤ï¼šä»0.72é™è‡³0.65ï¼Œåæ˜ éƒ¨åˆ†åŒ¹é…
                'base_overlap': 0.67,  # 4/6å­—æ®µå…±äº«
                'weighted_overlap': 0.67,
                'is_hard': True,
                'theme_a': 'hard_case',
                'theme_b': 'hard_case',
                'shared_fields': ['currency_code', 'date', 'amount', 'status'],
                'note': 'éƒ¨åˆ†é‡å ',
                'calc_details': {
                    'semantic_bonus': 0.0,
                    'struct_bonus': 0.02,
                    'variation_penalty': -0.01,
                    'synonym_bonus': 0.0
                }
            })

        # æ·»åŠ ç¡¬æ¡ˆä¾‹åˆ°ä¸»æ ‡æ³¨åˆ—è¡¨
        annotations.extend(hard_cases)
        print(f"   æ·»åŠ ç¡¬æ¡ˆä¾‹æ ‡æ³¨: {len(hard_cases)}å¯¹")

        # æ ‡ç­¾å¹³æ»‘ï¼ˆä¿å®ˆç­–ç•¥ï¼šåªå¹³æ»‘æç«¯å€¼ï¼‰
        for ann in annotations:
            sim = ann['similarity']
            # å°†æ¥è¿‘è¾¹ç•Œçš„å€¼ç¨å¾®æ¨å‘è¾¹ç•Œï¼Œé¿å…æ¨¡ç³Š
            if 0.35 <= sim < 0.4:
                ann['similarity'] = round(0.3 + random.random() * 0.05, 3)
            elif 0.6 < sim <= 0.65:
                ann['similarity'] = round(0.65 + random.random() * 0.05, 3)

        # é‡æ–°ç»Ÿè®¡
        hard_count = sum(
            1 for a in annotations if self.hard_min_threshold <= a['similarity'] <= self.hard_max_threshold)
        print(f"âœ… æ ‡æ³¨ç”Ÿæˆå®Œæˆï¼æ€»è®¡ {len(annotations)} å¯¹ï¼Œå›°éš¾æ ·æœ¬: {hard_count}å¯¹")

        # è®°å½•ç›¸ä¼¼åº¦åˆ†å¸ƒ
        sim_distribution = [a['similarity'] for a in annotations]
        self.generation_metadata['similarity_distribution'] = {
            'min': min(sim_distribution),
            'max': max(sim_distribution),
            'mean': sum(sim_distribution) / len(sim_distribution),
            'hard_count': hard_count
        }

        return annotations

    # ========== æ•°æ®é›†åˆ’åˆ†ï¼ˆå¸¦åˆ†å±‚é‡‡æ ·ï¼‰ ==========
    def generate_train_val_test_split(self, annotations: List[Dict]):
        """
        æ™ºèƒ½åˆ’åˆ†è®­ç»ƒ/éªŒè¯/æµ‹è¯•é›†ï¼šç¡®ä¿å›°éš¾æ ·æœ¬åˆ†å¸ƒå‡åŒ€

        ä¿®å¤ï¼š
        1. ä½¿ç”¨StratifiedSplitè€Œééšæœºåˆ’åˆ†
        2. æ˜¾å¼å¤„ç†ç¡¬æ¡ˆä¾‹
        3. ä¿å­˜åˆ’åˆ†å…ƒæ•°æ®
        """
        print("\n" + "-" * 40)
        print("æ•°æ®é›†åˆ’åˆ†...")

        # åˆ†ç¦»å›°éš¾æ ·æœ¬å’Œæ™®é€šæ ·æœ¬
        hard_samples = [a for a in annotations if a.get('is_hard', False)]
        normal_samples = [a for a in annotations if not a.get('is_hard', False)]

        print(f"   æ€»æ ·æœ¬: {len(annotations)}")
        print(f"   å›°éš¾æ ·æœ¬: {len(hard_samples)} ({len(hard_samples) / len(annotations) * 100:.1f}%)")
        print(f"   æ™®é€šæ ·æœ¬: {len(normal_samples)}")

        # åˆ†å±‚é‡‡æ ·ï¼šç¡®ä¿æ¯ä¸ªæ•°æ®é›†ä¸­ç¡¬æ¡ˆä¾‹æ¯”ä¾‹ä¸€è‡´
        hard_ratio = len(hard_samples) / len(annotations)

        # ç¡¬æ ·æœ¬åˆ’åˆ†
        train_hard, val_hard, test_hard = self._stratified_split(hard_samples, [0.7, 0.15, 0.15])

        # æ™®é€šæ ·æœ¬åˆ’åˆ†
        train_normal, val_normal, test_normal = self._stratified_split(normal_samples, [0.7, 0.15, 0.15])

        # åˆå¹¶å¹¶æ‰“ä¹±
        train_ann = self._shuffle_and_balance(train_hard, train_normal, hard_ratio)
        val_ann = self._shuffle_and_balance(val_hard, val_normal, hard_ratio)
        test_ann = self._shuffle_and_balance(test_hard, test_normal, hard_ratio)

        # ä¿å­˜åˆ°é…ç½®æŒ‡å®šè·¯å¾„
        self._save_annotations(train_ann, val_ann, test_ann, annotations)

        # æ‰“å°ç»Ÿè®¡
        print(f"\nğŸ“Š æ•°æ®é›†åˆ’åˆ†ç»Ÿè®¡:")
        print(f"   è®­ç»ƒé›†: {len(train_ann)} (å›°éš¾: {sum(1 for a in train_ann if a.get('is_hard', False))})")
        print(f"   éªŒè¯é›†: {len(val_ann)} (å›°éš¾: {sum(1 for a in val_ann if a.get('is_hard', False))})")
        print(f"   æµ‹è¯•é›†: {len(test_ann)} (å›°éš¾: {sum(1 for a in test_ann if a.get('is_hard', False))})")

        return train_ann, val_ann, test_ann

    def _stratified_split(self, data: List, ratios: List[float]):
        """åˆ†å±‚é‡‡æ ·ï¼ˆä¿æŒåŸåˆ—è¡¨é¡ºåºçš„éšæœºåˆ’åˆ†ï¼‰"""
        if not data:
            return [], [], []

        # å¤åˆ¶å¹¶æ‰“ä¹±
        data_copy = data.copy()
        random.shuffle(data_copy)

        n = len(data_copy)
        train_end = int(n * ratios[0])
        val_end = train_end + int(n * ratios[1])

        return data_copy[:train_end], data_copy[train_end:val_end], data_copy[val_end:]

    def _shuffle_and_balance(self, hard_part, normal_part, target_hard_ratio):
        """åˆå¹¶å¹¶ç¡®ä¿ç¡¬æ¡ˆä¾‹æ¯”ä¾‹"""
        combined = hard_part + normal_part

        # æ£€æŸ¥æ¯”ä¾‹æ˜¯å¦æ¥è¿‘ç›®æ ‡
        actual_hard_ratio = len(hard_part) / len(combined) if combined else 0
        if abs(actual_hard_ratio - target_hard_ratio) > 0.05:
            print(f"âš ï¸  ç¡¬æ¡ˆä¾‹æ¯”ä¾‹åç¦»: ç›®æ ‡{target_hard_ratio:.2f}, å®é™…{actual_hard_ratio:.2f}")

        random.shuffle(combined)
        return combined

    def _save_annotations(self, train_ann, val_ann, test_ann, all_ann):
        """ä¿å­˜æ ‡æ³¨æ–‡ä»¶ï¼ˆå¸¦å…ƒæ•°æ®ï¼‰"""
        data_cfg = self.config.get('data', {})
        output_dir = os.path.dirname(data_cfg.get('annotations_path', 'data/annotations.json'))
        os.makedirs(output_dir, exist_ok=True)

        # ä¿å­˜å…¨é‡æ ‡æ³¨
        with open(data_cfg.get('annotations_path', 'data/annotations.json'), 'w', encoding='utf-8') as f:
            json.dump(all_ann, f, ensure_ascii=False, indent=2)

        # ä¿å­˜åˆ’åˆ†
        paths = {
            'train': data_cfg.get('train_annotations', 'data/train_annotations.json'),
            'val': data_cfg.get('val_annotations', 'data/val_annotations.json'),
            'test': data_cfg.get('test_annotations', 'data/test_annotations.json')
        }

        for data, name in [(train_ann, 'train'), (val_ann, 'val'), (test_ann, 'test')]:
            with open(paths[name], 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            print(f"   ä¿å­˜ {paths[name]}: {len(data)} æ¡è®°å½•")

        # ä¿å­˜å…ƒæ•°æ®
        metadata_path = os.path.join(output_dir, 'generation_metadata.json')
        with open(metadata_path, 'w', encoding='utf-8') as f:
            # è½¬æ¢setä¸ºlistä»¥ä¾¿åºåˆ—åŒ–
            metadata_copy = self.generation_metadata.copy()
            metadata_copy['field_coverage'] = {k: list(v) for k, v in metadata_copy['field_coverage'].items()}
            json.dump(metadata_copy, f, ensure_ascii=False, indent=2)

    # ========== ä¸»å…¥å£ ==========
    def generate_full_dataset(self, show_stats: bool = True):
        """ä¸€é”®ç”Ÿæˆå®Œæ•´æ•°æ®é›†"""
        # 1. ç”Ÿæˆè¡¨
        tables = self.generate_massive_tables()

        # 2. ç”Ÿæˆæ ‡æ³¨
        annotations = self.generate_enhanced_annotations(tables)

        # 3. åˆ’åˆ†æ•°æ®é›†
        train, val, test = self.generate_train_val_test_split(annotations)

        if show_stats:
            self._print_final_stats(tables, annotations, train, val, test)

        return tables, annotations, train, val, test

    def _print_final_stats(self, tables, annotations, train, val, test):
        """æ‰“å°æœ€ç»ˆç»Ÿè®¡"""
        print("\n" + "=" * 60)
        print("ğŸ“Š æœ€ç»ˆæ•°æ®é›†ç»Ÿè®¡")
        print("=" * 60)

        sim_values = [a['similarity'] for a in annotations]

        print(f"è¡¨ç”Ÿæˆ:")
        print(f"  - æ€»è¡¨æ•°: {len(tables)}")
        print(f"  - ä¸»é¢˜è¦†ç›–: {len(self.themes)}ä¸ª")

        print(f"\næ ‡æ³¨ç»Ÿè®¡:")
        print(f"  - æ€»å¯¹æ•°: {len(annotations)}")
        print(f"  - ç›¸ä¼¼åº¦èŒƒå›´: {min(sim_values):.3f} - {max(sim_values):.3f}")
        print(f"  - å‡å€¼: {sum(sim_values) / len(sim_values):.3f}")
        print(f"  - å›°éš¾æ ·æœ¬: {sum(1 for a in annotations if a.get('is_hard', False))}å¯¹")

        print(f"\nåˆ’åˆ†ç»Ÿè®¡:")
        print(f"  - è®­ç»ƒé›†: {len(train)} ({len(train) / len(annotations) * 100:.1f}%)")
        print(f"  - éªŒè¯é›†: {len(val)} ({len(val) / len(annotations) * 100:.1f}%)")
        print(f"  - æµ‹è¯•é›†: {len(test)} ({len(test) / len(annotations) * 100:.1f}%)")

        # ç¡¬æ¡ˆä¾‹åˆ†å¸ƒ
        for name, data in [('è®­ç»ƒé›†', train), ('éªŒè¯é›†', val), ('æµ‹è¯•é›†', test)]:
            hard_in_set = sum(1 for a in data if a.get('is_hard', False))
            print(f"    {name}å›°éš¾æ ·æœ¬: {hard_in_set}å¯¹ ({hard_in_set / len(data) * 100:.1f}%)")

        print("\n" + "=" * 60)


def main():
    """ä¸»å…¥å£ï¼ˆå¸¦å‘½ä»¤è¡Œå‚æ•°ï¼‰"""
    parser = argparse.ArgumentParser(description="ç”Ÿæˆå¤§è§„æ¨¡è¡¨ç›¸ä¼¼æ€§æ•°æ®é›†ï¼ˆç”Ÿäº§å°±ç»ªç‰ˆï¼‰")
    parser.add_argument("--config", default="config.yml", help="é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤: config.ymlï¼‰")
    parser.add_argument("--show_stats", action="store_true", help="æ˜¾ç¤ºè¯¦ç»†ç»Ÿè®¡ä¿¡æ¯")
    parser.add_argument("--validate_only", action="store_true", help="ä»…éªŒè¯æ•°æ®è´¨é‡ï¼Œä¸ç”Ÿæˆ")
    parser.add_argument("--clean", action="store_true", help="ç”Ÿæˆå‰æ¸…ç†æ—§æ•°æ®")

    args = parser.parse_args()

    # æ£€æŸ¥é…ç½®æ–‡ä»¶
    if not os.path.exists(args.config):
        print(f"âŒ é”™è¯¯ï¼šé…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {args.config}")
        print("è¯·ç¡®ä¿ config.yml æ–‡ä»¶å­˜åœ¨äºå½“å‰ç›®å½•æˆ–æŒ‡å®šæ­£ç¡®è·¯å¾„")
        return

    print("\n" + "=" * 60)
    print("ğŸš€ å¢å¼ºå‹æ•°æ®é›†ç”Ÿæˆå¼€å§‹ï¼ˆç”Ÿäº§å°±ç»ªç‰ˆï¼‰")
    print(f"ğŸ“„ é…ç½®æ–‡ä»¶: {args.config}")
    print("=" * 60 + "\n")

    try:
        # åˆ›å»ºç”Ÿæˆå™¨
        generator = EnhancedDatasetGenerator(args.config)

        if args.validate_only:
            # ä»…éªŒè¯æ¨¡å¼
            print("ğŸ” ä»…éªŒè¯æ•°æ®è´¨é‡...")
            # è¿™é‡Œå¯ä»¥åŠ è½½ç°æœ‰æ•°æ®è¿›è¡ŒéªŒè¯
            return

        # ç”Ÿæˆå®Œæ•´æ•°æ®é›†
        tables, annotations, train, val, test = generator.generate_full_dataset(show_stats=args.show_stats)

        # éªŒè¯æ–‡ä»¶å®Œæ•´æ€§
        data_cfg = generator.config.get('data', {})
        required_files = [
            data_cfg.get('annotations_path', 'data/annotations.json'),
            data_cfg.get('train_annotations', 'data/train_annotations.json'),
            data_cfg.get('val_annotations', 'data/val_annotations.json'),
            data_cfg.get('test_annotations', 'data/test_annotations.json')
        ]

        all_exist = all(os.path.exists(f) for f in required_files)
        if all_exist:
            print("\nâœ… æ‰€æœ‰æ ‡æ³¨æ–‡ä»¶ç”ŸæˆæˆåŠŸï¼")
        else:
            missing = [f for f in required_files if not os.path.exists(f)]
            print(f"\nâŒ ä»¥ä¸‹æ–‡ä»¶ç¼ºå¤±: {missing}")

        print("\n" + "=" * 60)
        print("âœ… æ•°æ®é›†ç”Ÿæˆå®Œæˆï¼")
        print("=" * 60 + "\n")

        print("ä¸‹ä¸€æ­¥æ“ä½œ:")
        print("1. python build_knowledge_graph.py  # æ„å»ºçŸ¥è¯†å›¾è°±")
        print("2. python train.py                    # å¼€å§‹è®­ç»ƒ")
        print("3. python vector_store.py --rebuild   # æ„å»ºå‘é‡åº“")

    except Exception as e:
        print(f"\nâŒ ç”Ÿæˆè¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
        import traceback
        traceback.print_exc()
        raise
if __name__ == "__main__":
    main()
